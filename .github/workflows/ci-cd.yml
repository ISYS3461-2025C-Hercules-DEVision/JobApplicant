name: CI + CD (Build/Test + Push to ECR + Deploy to EC2)

on:
  pull_request:
    branches: ["main"]
  push:
    branches: ["main"]
  workflow_dispatch:

env:
  AWS_REGION: ${{ secrets.AWS_REGION }}
  AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
  ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com
  ECR_NAMESPACE: ja-devision-platform

jobs:
  # -----------------------------
  # CI: Build (and optional test)
  # Runs on PRs and pushes
  # -----------------------------
  ci:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: api-gateway
            folder: backend/api-gateway
            type: java
          - name: applicant
            folder: backend/applicant
            type: java
          - name: authentication
            folder: backend/authentication
            type: java
          - name: discovery-server
            folder: backend/discovery-server
            type: java
          - name: admin
            folder: backend/admin
            type: java
          - name: frontend
            folder: frontend
            type: node
          - name: subscription
            folder: backend/subscription
            type: java
          - name: application
            folder: backend/application
            type: java

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # ---- Java setup ----
      - name: Setup Java 21
        if: matrix.type == 'java'
        uses: actions/setup-java@v4
        with:
          distribution: "temurin"
          java-version: "21"
          cache: "maven"

      - name: Setup Maven
        if: matrix.type == 'java'
        uses: stCarolas/setup-maven@v5
        with:
          maven-version: 3.9.9

      - name: Build Java service (skip tests)
        if: matrix.type == 'java'
        working-directory: ./${{ matrix.folder }}
        run: mvn -B -DskipTests clean package

      # ---- Node setup ----
      - name: Setup Node.js
        if: matrix.type == 'node'
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"
          cache-dependency-path: ./${{ matrix.folder }}/package-lock.json

      - name: Build frontend
        if: matrix.type == 'node'
        working-directory: ./${{ matrix.folder }}
        run: |
          npm ci
          npm run build

  # -----------------------------
  # CD (Frontend): Build + Upload to S3 + Invalidate CloudFront
  # Runs ONLY on push to main
  # -----------------------------
  deploy_frontend:
    needs: ci
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest

    env:
      FRONTEND_S3_BUCKET: job-applicant.indevs.in
      CLOUDFRONT_DISTRIBUTION_ID: ${{ secrets.FRONTEND_CLOUDFRONT_DISTRIBUTION_ID }}
      FRONTEND_BUILD_DIR: dist

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"
          cache-dependency-path: ./frontend/package-lock.json

      # ✅ Build with production API base (Vite example)
      # If you don't use Vite, tell me your tool (CRA/Next) and I'll adjust env names.
      - name: Build frontend (production)
        working-directory: ./frontend
        env:
          VITE_API_BASE: ${{ secrets.VITE_API_BASE }}
          VITE_API_BASE_JOB_MANAGER: ${{ secrets.VITE_API_BASE_JOB_MANAGER }}
        run: |
          npm ci
          npm run build

      # ✅ Upload to S3 under /dist because your CloudFront Origin Path is /dist
      - name: Sync build to S3 (/dist)
        run: |
          set -euo pipefail
          aws s3 sync "./frontend/${FRONTEND_BUILD_DIR}/" "s3://${FRONTEND_S3_BUCKET}/dist/" --delete

      # ✅ Prevent index.html being cached too long
      - name: Set no-cache for index.html
        run: |
          set -euo pipefail
          aws s3 cp "s3://${FRONTEND_S3_BUCKET}/dist/index.html" "s3://${FRONTEND_S3_BUCKET}/dist/index.html" \
            --metadata-directive REPLACE \
            --cache-control "no-cache, no-store, must-revalidate" \
            --content-type "text/html"

      - name: Invalidate CloudFront
        run: |
          set -euo pipefail
          aws cloudfront create-invalidation \
            --distribution-id "${CLOUDFRONT_DISTRIBUTION_ID}" \
            --paths "/*"

  # -----------------------------
  # CD: Build Docker images + push to ECR
  # + Deploy backend to EC2
  # Runs ONLY on push to main
  # -----------------------------
  cd:
    needs: ci
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          # ✅ BACKEND ONLY (no frontend deploy)
          - folder: backend/api-gateway
            repo: api-gateway
            container_name: api-gateway
            host_port: "10789:10789"
            env_secret: ENV_GATEWAY
            target_host: gateway

          - folder: backend/discovery-server
            repo: discovery-server
            container_name: discovery-server
            host_port: "8761:8761"
            env_secret: ENV_DISCOVERY
            target_host: gateway

          - folder: backend/authentication
            repo: authentication-service
            container_name: authentication-service
            host_port: "8087:8087"
            env_secret: ENV_AUTH
            target_host: service01

          - folder: backend/admin
            repo: admin
            container_name: admin-service
            host_port: "8088:8088"
            env_secret: ENV_ADMIN
            target_host: service01

          - folder: backend/applicant
            repo: applicant-service
            container_name: applicant-service
            host_port: "8083:8083"
            env_secret: ENV_APPLICANT
            target_host: service02

          - folder: backend/subscription
            repo: subscription
            container_name: subscription-service
            host_port: "8086:8086"
            env_secret: ENV_SUBSCRIPTION
            target_host: service03

          - folder: backend/application
            repo: application
            container_name: application-service
            host_port: "8084:8084"
            env_secret: ENV_APPLICATION
            target_host: service03

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      # ✅ Push Redis image to ECR (ONLY ONCE PER WORKFLOW RUN)
      - name: Push Redis image to ECR
        if: matrix.repo == 'api-gateway'
        run: |
          set -euo pipefail
          SHA_TAG="${GITHUB_SHA::7}"
          IMAGE_URI="${ECR_REGISTRY}/${ECR_NAMESPACE}/redis"

          echo "Pulling redis:7-alpine..."
          docker pull redis:7-alpine

          echo "Tagging..."
          docker tag redis:7-alpine ${IMAGE_URI}:latest
          docker tag redis:7-alpine ${IMAGE_URI}:${SHA_TAG}

          echo "Pushing to ECR..."
          docker push ${IMAGE_URI}:latest
          docker push ${IMAGE_URI}:${SHA_TAG}

          echo "✅ Redis pushed: ${IMAGE_URI}"

      # ✅ Build & Push backend Docker image
      - name: Build & Push Docker image
        run: |
          set -euo pipefail
          SHA_TAG="${GITHUB_SHA::7}"
          IMAGE_URI="${ECR_REGISTRY}/${ECR_NAMESPACE}/${{ matrix.repo }}"

          echo "Building from folder: ${{ matrix.folder }}"
          echo "Pushing to: ${IMAGE_URI}"

          docker build \
            -t ${IMAGE_URI}:latest \
            -t ${IMAGE_URI}:${SHA_TAG} \
            ./${{ matrix.folder }}

          docker push ${IMAGE_URI}:latest
          docker push ${IMAGE_URI}:${SHA_TAG}

          echo "✅ Done: ${IMAGE_URI} pushed"

      # -----------------------------
      # SSH Setup
      # - gateway uses key_gateway
      # - service01 uses key_service01 (ProxyJump gateway)
      # - service02 uses key_service02 (ProxyJump gateway)
      # - service03 uses key_gateway (ProxyJump gateway)
      # -----------------------------
      - name: Setup SSH keys (gateway + service01 + service02 + service03)
        env:
          SSH_USER: ${{ secrets.EC2_SSH_USER }}
          GATEWAY_IP: ${{ secrets.EC2_GATEWAY_PUBLIC_IP }}
          SERVICE01_IP: ${{ secrets.EC2_SERVICE01_PRIVATE_IP }}
          SERVICE02_IP: ${{ secrets.EC2_SERVICE02_PRIVATE_IP }}
          SERVICE03_IP: ${{ secrets.EC2_SERVICE03_PRIVATE_IP }}

          KEY_GATEWAY_B64: ${{ secrets.EC2_SSH_PRIVATE_KEY_GATEWAY_B64 }}
          KEY_SERVICE01_B64: ${{ secrets.EC2_SSH_PRIVATE_KEY_SERVICE01_B64 }}
          KEY_SERVICE02_B64: ${{ secrets.EC2_SSH_PRIVATE_KEY_SERVICE02_B64 }}
        run: |
          set -euo pipefail
          mkdir -p ~/.ssh

          echo "$KEY_GATEWAY_B64"   | base64 -d | tr -d '\r' > ~/.ssh/key_gateway
          echo "$KEY_SERVICE01_B64" | base64 -d | tr -d '\r' > ~/.ssh/key_service01
          echo "$KEY_SERVICE02_B64" | base64 -d | tr -d '\r' > ~/.ssh/key_service02

          chmod 600 ~/.ssh/key_gateway ~/.ssh/key_service01 ~/.ssh/key_service02

          cat > ~/.ssh/config <<CFG
          Host gateway
            HostName ${GATEWAY_IP}
            User ${SSH_USER}
            IdentityFile ~/.ssh/key_gateway
            IdentitiesOnly yes
            StrictHostKeyChecking no

          Host service01
            HostName ${SERVICE01_IP}
            User ${SSH_USER}
            IdentityFile ~/.ssh/key_service01
            IdentitiesOnly yes
            ProxyJump gateway
            StrictHostKeyChecking no

          Host service02
            HostName ${SERVICE02_IP}
            User ${SSH_USER}
            IdentityFile ~/.ssh/key_service02
            IdentitiesOnly yes
            ProxyJump gateway
            StrictHostKeyChecking no

          Host service03
            HostName ${SERVICE03_IP}
            User ${SSH_USER}
            IdentityFile ~/.ssh/key_gateway
            IdentitiesOnly yes
            ProxyJump gateway
            StrictHostKeyChecking no
          CFG

          chmod 600 ~/.ssh/config

      - name: Test SSH to Gateway
        run: |
          set -euo pipefail
          ssh gateway "echo SSH_OK && hostname"

      - name: Test SSH to service01
        run: |
          set -euo pipefail
          ssh service01 "echo SERVICE01_OK && hostname"

      - name: Test SSH to service02
        run: |
          set -euo pipefail
          ssh service02 "echo SERVICE02_OK && hostname"

      - name: Test SSH to service03
        run: |
          set -euo pipefail
          ssh service03 "echo SERVICE03_OK && hostname"

      # -----------------------------
      # Deploy backend to EC2
      # -----------------------------
      - name: Deploy to EC2
        env:
          IMAGE_URI: ${{ env.ECR_REGISTRY }}/${{ env.ECR_NAMESPACE }}/${{ matrix.repo }}:latest
          CONTAINER_NAME: ${{ matrix.container_name }}
          HOST_PORT: ${{ matrix.host_port }}
          ENV_CONTENT_B64: ${{ secrets[matrix.env_secret] }}
          TARGET_HOST: ${{ matrix.target_host }}

          AWS_REGION: ${{ env.AWS_REGION }}
          ECR_REGISTRY: ${{ env.ECR_REGISTRY }}
        run: |
          set -euo pipefail

          if [ "$TARGET_HOST" = "gateway" ]; then
            SSH_HOST="gateway"
          elif [ "$TARGET_HOST" = "service01" ]; then
            SSH_HOST="service01"
          elif [ "$TARGET_HOST" = "service02" ]; then
            SSH_HOST="service02"
          elif [ "$TARGET_HOST" = "service03" ]; then
            SSH_HOST="service03"
          else
            echo "Unknown TARGET_HOST=$TARGET_HOST"
            exit 1
          fi

          echo "Deploying ${CONTAINER_NAME} to ${SSH_HOST}"
          echo "Image: ${IMAGE_URI}"

          ssh "${SSH_HOST}" "echo ok" >/dev/null

          ssh "${SSH_HOST}" \
            "IMAGE_URI='${IMAGE_URI}' CONTAINER_NAME='${CONTAINER_NAME}' HOST_PORT='${HOST_PORT}' ENV_CONTENT_B64='${ENV_CONTENT_B64}' AWS_REGION='${AWS_REGION}' ECR_REGISTRY='${ECR_REGISTRY}' bash -s" << 'EOF'
          set -euo pipefail

          sudo mkdir -p /opt/ja/env

          echo "${ENV_CONTENT_B64}" | base64 -d | sudo tee /opt/ja/env/${CONTAINER_NAME}.env > /dev/null
          sudo chmod 600 /opt/ja/env/${CONTAINER_NAME}.env

          echo "Login to ECR..."
          aws ecr get-login-password --region ${AWS_REGION} | sudo docker login --username AWS --password-stdin ${ECR_REGISTRY}

          echo "Pulling image..."
          sudo docker pull ${IMAGE_URI}

          echo "Stopping old container..."
          sudo docker rm -f ${CONTAINER_NAME} || true

          echo "Starting new container..."
          sudo docker run -d \
            --restart unless-stopped \
            --name ${CONTAINER_NAME} \
            --env-file /opt/ja/env/${CONTAINER_NAME}.env \
            -p ${HOST_PORT} \
            ${IMAGE_URI}

          echo "✅ Container running:"
          sudo docker ps --filter "name=${CONTAINER_NAME}"

          echo "✅ Last 50 logs:"
          sudo docker logs --tail 50 ${CONTAINER_NAME} || true
          EOF
